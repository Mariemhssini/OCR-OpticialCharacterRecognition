{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedehab00/A-Hybrid-Arabic-Text-Summarization-Approach-based-on-Transformers/blob/main/TextClassificationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "lPhtz0FXp1PJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KilZhdzypmWt",
        "outputId": "6b6272bd-f780-43bd-fa59-796b915d8834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing,metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "st = ISRIStemmer()\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('arabic')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "dpStRrqeq2NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean(text):\n",
        "  #remove all English chars\n",
        "  text = re.sub(r'\\s*[A-Za-z]\\s*', ' ' , text)\n",
        "  #remove hashtags\n",
        "  text = re.sub(\"#\", \" \", text)\n",
        "  #remove all numbers\n",
        "  text = re.sub(r'\\[0-9]*\\]',' ',text)\n",
        "  #remove duplicated chars\n",
        "  text = re.sub(r'(.)\\1+', r'\\1', text)\n",
        "  #remove :) or :(\n",
        "  text = text.replace(':)', \"\")\n",
        "  text = text.replace(':(', \"\")\n",
        "  #remove multiple exclamation\n",
        "  text = re.sub(r\"(\\!)\\1+\", ' ', text)\n",
        "  #remove multiple question marks\n",
        "  text = re.sub(r\"(\\?)\\1+\", ' ', text)\n",
        "  #remove multistop\n",
        "  text = re.sub(r\"(\\.)\\1+\", ' ', text)\n",
        "  #remove additional spaces\n",
        "  text = re.sub(r\"[\\s]+\", \" \", text)\n",
        "  text = re.sub(r\"[\\n]+\", \" \", text)\n",
        "\n",
        "  return text\n",
        "\n",
        "def remStopWords(Text):\n",
        "  return \" \".join(word for word in Text.split() if word not in stop)\n",
        "\n",
        "def stemWords(Text):\n",
        "  return \" \".join(st.stem(word) for word in Text.split())"
      ],
      "metadata": {
        "id": "sXScNyctr2L8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read data\n",
        "dataFrame = pd.read_csv('/content/Sampled_File_with_SMOTE.csv')\n",
        "\n",
        "dataFrame['text']=dataFrame['text'].apply(lambda Text: remStopWords(str(Text)))\n",
        "dataFrame['text'] = dataFrame['text'].apply(lambda Text : clean(Text))\n",
        "dataFrame['text']=dataFrame['text'].apply(lambda Text: stemWords(Text))\n",
        "\n",
        "dataFrame.drop_duplicates(subset =\"text\",keep = 'first', inplace = True)\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(dataFrame['text'], dataFrame['class'],test_size=0.2,random_state=11)\n",
        "\n",
        "before_encode_valid_y = dataFrame['class'].unique()\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word',token_pattern=r'\\w{1,}', max_features=5000)\n",
        "\n",
        "tfidf_vect.fit(dataFrame['text'])\n",
        "\n",
        "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf = tfidf_vect.transform(valid_x)"
      ],
      "metadata": {
        "id": "8dCzqSvbsa9I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "7459GNT0q2f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(classifier, feature_vector_train, label,feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    return metrics.accuracy_score(predictions, valid_y),predictions"
      ],
      "metadata": {
        "id": "sLlYDviBr9Hf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "clf_svm = GridSearchCV(SVC(), params_grid, cv=5)"
      ],
      "metadata": {
        "id": "w9v5N-zxstO3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, predictions = train_model(clf_svm,xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "\n",
        "print(\"accuracy: \",accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfEhBC7Pswqu",
        "outputId": "a3c04983-6e0e-4743-c374-796e5c8458f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  97.56309834638816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model To Pickle"
      ],
      "metadata": {
        "id": "B6XwZJW7rc3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "directory = '/content/Pickles/'\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Now you can proceed with opening the pickle files\n",
        "pklClassifierFile = open('/content/Pickles/TextClassifier.pkl', 'wb')\n",
        "pklEncodingFile = open('/content/Pickles/LabelEncoder.pkl', 'wb')\n",
        "pklVectorizerFile = open('/content/Pickles/TextVectorizer.pkl', 'wb')\n",
        "\n",
        "# source, destination\n",
        "pickle.dump(clf_svm, pklClassifierFile)\n",
        "pklClassifierFile.close()\n",
        "# source, destination\n",
        "pickle.dump(encoder, pklEncodingFile)\n",
        "pklEncodingFile.close()\n",
        "# source, destination\n",
        "pickle.dump(tfidf_vect, pklVectorizerFile)\n",
        "pklVectorizerFile.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "OkPsOLZKr-S3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Of Generated Pickles"
      ],
      "metadata": {
        "id": "jbx2osgbwGxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_svm = pickle.load(open('/content/Pickles/TextClassifier.pkl', 'rb'))\n",
        "\n",
        "encoder = pickle.load(open('/content/Pickles/LabelEncoder.pkl', 'rb'))\n",
        "\n",
        "tfidf_vect = pickle.load(open('/content/Pickles/TextVectorizer.pkl', 'rb'))\n"
      ],
      "metadata": {
        "id": "UiMHuVn0w-Gu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textInput = \"كرة القدم من أكثر الالعاب الرياضية انتشارا في العالم وأقدمها[بحاجة لمصدر]. يعتبر كأس العالم لكرة القدم أكبر محفل دولي في مجال هذه اللعبة الرياضية و يطمح كل بلد في العالم في الحصول عليه.كرة القدم رياضة يتبارى فيها فريقان في ملعب ذو أرضية مزروعة على جانبيه مرميان ، و الفكرة في كرة القدم هي محاولة إيداع الكرة في مرمى الخصم ؛ و ذلك باستخدام الأرجل و الرأس غالبا ، حيث لا يسمح باستخدام اليدين إلا لحارس المرمى . يتكون كل فريق من 11 لاعبا ، يتواجد أثناء المباريات الرسمية حكم ساحة و مساعدين اثنين له على جوانب الملعب كرة القدم تلعب على مستوى احترافي في كل أنحاء العالم ، و الآلاف من عشاقها يذهبون إلى الملاعب لتشجيع فرقهم المفضلة ، بينما الملايين من الناس يشاهدون هذه الرياضة على التلفاز . عدد كبير جدا من الناس أيضا يمارسون رياضة كرة القدم بمستويات أقل احترافا . يذكر أن المباراة النهائية لكأس العالم لكرة القدم 2002 شاهدها أكثر من مليار و ثمان مئة مليون شخص حول العالم وهو ما يقارب نسبة 28% من سكان الكرة الأرضية يحكم كرة القدم الاتحاد الدولي لكرة القدم -الفيفا- و الذي يقوم بتنظيم هذه اللعبة وقوانينها حول العالم . وفقا للإحصائيات التي أعلنتها الفيفا FIFA في ربيع عام 2001 ، فإن أكثر من 240 مليون شخص يلعبون كرة القدم بانتظام في أكثر من 200 بلدة في كل أنحاء العالم[1].تقام العديد من بطولات كرة القدم أهمها على الاطلاق بطولة كأس العالم والتي تقام كل أربع سنوات ثم كأس الأمم الأوربية ودوري أبطال أوروبا وهناك أيضا بطولة الأمم الافريقية وبطولة الأمم الأسيوية وكوبا أمريكا وكأس العالم للشباب و غيرها.\""
      ],
      "metadata": {
        "id": "bJCKXygywHLK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(Text):\n",
        "  #preprocessing step\n",
        "  Text = clean(Text)\n",
        "  Text = \"\".join([char for char in Text if char not in string.ascii_letters]).strip()\n",
        "  Text = remStopWords(str(Text))\n",
        "  Text = stemWords(Text)\n",
        "  #vectorize the text\n",
        "  Text_Vector = tfidf_vect.transform([Text])\n",
        "  predictions = clf_svm.predict(Text_Vector)\n",
        "  return encoder.inverse_transform(predictions)[0]"
      ],
      "metadata": {
        "id": "d8PLshShwaxC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline(textInput))\n",
        "print(\"DONE!!!\")"
      ],
      "metadata": {
        "id": "VyGDnue3wlJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86383356-ba64-4b50-8b1c-2ea74a9103cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "رياضة\n",
            "DONE!!!\n"
          ]
        }
      ]
    }
  ]
}